{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXWyqAF7KNYAuxe2AX850n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariaaseret/MDE/blob/main/Aula8_MariaTeresa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação das Bibliotecas"
      ],
      "metadata": {
        "id": "96T0ff4_5Der"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "Flz2wPpH0Qca"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregamento dos Dados:\n",
        "\n",
        "## Estrutura dos dados:\n",
        "\n",
        "* UNIQUEID: Identificador único para cada observação.\n",
        "* SCHOOL: A escola onde a observação foi feita.\n",
        "* Class: A classe onde a observação foi feita.\n",
        "* GRADE: O grau escolar dos estudantes.\n",
        "* CODER: Identificador do avaliador que fez a observação.\n",
        "* STUDENTID: Identificador único do estudante.\n",
        "* Gender: Gênero do estudante.\n",
        "* OBSNUM: Número da observação para o estudante.\n",
        "* totalobs-forsession: Contagem total de observações para a sessão.\n",
        "* Activity: A atividade que estava sendo realizada.\n",
        "* ONTASK: Variável alvo, indicando se o estudante estava engajado (Y=Yes) ou distraído (N=No).\n",
        "* TRANSITIONS: Número de transições de atividades.\n",
        "* NumACTIVITIES: Número de atividades diferentes observadas.\n",
        "* FORMATchanges: Mudanças de formato da atividade.\n",
        "* NumFORMATS: Número de formatos diferentes de atividades.\n",
        "* Obsv/act: Observação por atividade.\n",
        "* Transitions/Durations: Razão entre transições e durações.\n",
        "* Total Time: Tempo total gasto na atividade.\n",
        "\n",
        "------\n",
        "\n",
        "## Segundo o artigo as variáveis utilizadas são:\n",
        "\n",
        "As variáveis utilizadas como preditoras foram separadas em duas categorias: característica do aluno (gender, grade -- gênero e série) e design instrucional (Activity, Transitions/Durations -- formato da instrução e Transições/Duração).\n",
        "\n"
      ],
      "metadata": {
        "id": "Q0edTVto5Fxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar dados\n",
        "data = pd.read_csv('/content/a1-in.csv')"
      ],
      "metadata": {
        "id": "WA1HhwYx0RZZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-processamento e Seleção de Variáveis"
      ],
      "metadata": {
        "id": "AHjlmkkC5IAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionando as variáveis relevantes conforme a tarefa\n",
        "features = data[['Gender', 'GRADE', 'Activity', 'Transitions/Durations']]\n",
        "target = data['ONTASK']\n",
        "\n",
        "# Conversão de 'ONTASK' para binário\n",
        "target = target.map({'Y': 1, 'N': 0})"
      ],
      "metadata": {
        "id": "DjApffOj0Vix"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divisão dos Dados em Treino e Teste"
      ],
      "metadata": {
        "id": "ucrjklX45lPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5tY47Sxk0Xny"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construção do Pipeline"
      ],
      "metadata": {
        "id": "0Q6fleTR5nHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline para tratamento numérico e categórico\n",
        "numeric_features = ['GRADE', 'Transitions/Durations']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['Gender', 'Activity']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# Combinar transformadores\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Modelos a serem avaliados\n",
        "classifiers = [\n",
        "    ('logreg', LogisticRegression(max_iter=1000)),\n",
        "    ('rf', RandomForestClassifier()),\n",
        "    ('dt', DecisionTreeClassifier()),\n",
        "    ('svc', SVC())\n",
        "]\n",
        "\n",
        "# Grids de hiperparâmetros para GridSearchCV\n",
        "param_grids = {\n",
        "    'logreg': {'classifier__C': [0.1, 1, 10]},\n",
        "    'rf': {'classifier__n_estimators': [50, 100, 200]},\n",
        "    'dt': {'classifier__max_depth': [None, 10, 20, 30]},\n",
        "    'svc': {'classifier__C': [0.1, 1, 10]}\n",
        "}"
      ],
      "metadata": {
        "id": "qRama5yh0ZXp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento e Otimização com GridSearchCV"
      ],
      "metadata": {
        "id": "ojATES5h5n9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = {}\n",
        "for name, classifier in classifiers:\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('classifier', classifier)])\n",
        "    # GridSearchCV para encontrar os melhores parâmetros\n",
        "    grid_search = GridSearchCV(pipeline, param_grids[name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_models[name] = grid_search.best_estimator_\n",
        "    print(f\"Melhor modelo para {name}: {grid_search.best_params_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOdZ5V-G0ZxT",
        "outputId": "90ea44be-cc31-40c1-bf0b-edc022529533"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhor modelo para logreg: {'classifier__C': 0.1}\n",
            "Melhor modelo para rf: {'classifier__n_estimators': 200}\n",
            "Melhor modelo para dt: {'classifier__max_depth': 10}\n",
            "Melhor modelo para svc: {'classifier__C': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avaliação dos Modelos"
      ],
      "metadata": {
        "id": "Hl5UARIG5qSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Relatório de classificação para o modelo {name}:\")\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E98c_7NJ0r86",
        "outputId": "9d5c948b-dd91-4ede-e4f0-34982f40ab56"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatório de classificação para o modelo logreg:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1790\n",
            "           1       0.68      1.00      0.81      3757\n",
            "\n",
            "    accuracy                           0.68      5547\n",
            "   macro avg       0.34      0.50      0.40      5547\n",
            "weighted avg       0.46      0.68      0.55      5547\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatório de classificação para o modelo rf:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.18      0.27      1790\n",
            "           1       0.71      0.93      0.80      3757\n",
            "\n",
            "    accuracy                           0.69      5547\n",
            "   macro avg       0.64      0.56      0.54      5547\n",
            "weighted avg       0.66      0.69      0.63      5547\n",
            "\n",
            "Relatório de classificação para o modelo dt:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.16      0.25      1790\n",
            "           1       0.70      0.94      0.80      3757\n",
            "\n",
            "    accuracy                           0.69      5547\n",
            "   macro avg       0.63      0.55      0.52      5547\n",
            "weighted avg       0.66      0.69      0.62      5547\n",
            "\n",
            "Relatório de classificação para o modelo svc:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.01      0.03      1790\n",
            "           1       0.68      1.00      0.81      3757\n",
            "\n",
            "    accuracy                           0.68      5547\n",
            "   macro avg       0.70      0.51      0.42      5547\n",
            "weighted avg       0.69      0.68      0.56      5547\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise de Melhor Modelo\n",
        "\n",
        "Após a avaliação de diversos modelos de classificação binária, o modelo de **Floresta Aleatória (Random Forest)** se destacou como o mais promissor para a tarefa de prever comportamentos on-task e off-task em ambientes educacionais. Os resultados obtidos foram comparados baseando-se em métricas de precisão, recall e F1-score para ambas as classes (on-task e off-task).\n",
        "\n",
        "### Resultados do Modelo de Floresta Aleatória:\n",
        "- **Precisão para on-task (1):** 71%\n",
        "- **Recall para on-task (1):** 93%\n",
        "- **F1-score para on-task (1):** 80%\n",
        "- **Precisão para off-task (0):** 57%\n",
        "- **Recall para off-task (0):** 18%\n",
        "- **F1-score para off-task (0):** 27%\n",
        "\n",
        "### Justificativa para a Escolha:\n",
        "O modelo de Floresta Aleatória demonstrou um equilíbrio relativamente melhor entre precisão e recall para ambas as classes em comparação com os outros modelos testados. Apesar de os valores de recall e F1-score para a classe off-task ainda serem baixos, este modelo conseguiu atingir uma precisão e F1-score consideráveis para a classe on-task, que compõe a maioria dos casos.\n",
        "\n",
        "### Importância das Métricas:\n",
        "O **recall** é crucial, especialmente para a classe off-task, pois indica a capacidade do modelo de capturar todos os casos relevantes de desengajamento. Um alto recall na classe off-task significa que o sistema é capaz de identificar eficientemente os alunos que precisam de atenção adicional, possibilitando intervenções educacionais mais eficazes.\n",
        "\n",
        "O **F1-score** também é uma métrica importante, pois equilibra a precisão e o recall, sendo particularmente útil em situações com classes desbalanceadas como esta. O F1-score mais alto para on-task mostra que o modelo é competente em identificar o engajamento dos alunos, mas é necessário melhorar o F1-score para off-task para tornar o modelo mais útil em ambientes educacionais práticos.\n"
      ],
      "metadata": {
        "id": "yC9HYDfG7mAE"
      }
    }
  ]
}