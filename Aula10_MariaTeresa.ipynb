{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoDKRKHWZ1vgTI3Z98B/zz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#aula 8 na íntegra: (Criação de Cópia e Escolha do Modelo)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC  # Import for Support Vector Classifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Carregar dados\n",
        "data = pd.read_csv('/content/a1-in.csv')\n",
        "data = data.dropna().drop_duplicates()\n",
        "\n",
        "# Selecionando as variáveis relevantes conforme a tarefa\n",
        "features = data[['Gender', 'GRADE', 'Activity', 'Transitions/Durations']]\n",
        "target = data['ONTASK']\n",
        "\n",
        "# Conversão de 'ONTASK' para binário\n",
        "target = target.map({'Y': 1, 'N': 0})\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pipeline para tratamento numérico e categórico\n",
        "numeric_features = ['GRADE', 'Transitions/Durations']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['Gender', 'Activity']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# Combinar transformadores\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Modelos a serem avaliados\n",
        "classifiers = [\n",
        "    ('logreg', LogisticRegression(max_iter=1000)),\n",
        "    ('rf', RandomForestClassifier()),\n",
        "    ('dt', DecisionTreeClassifier()),\n",
        "    ('svc', SVC())\n",
        "]\n",
        "\n",
        "# Grids de hiperparâmetros para GridSearchCV\n",
        "param_grids = {\n",
        "    'logreg': {'classifier__C': [0.1, 1, 10]},\n",
        "    'rf': {'classifier__n_estimators': [50, 100, 200]},\n",
        "    'dt': {'classifier__max_depth': [None, 10, 20, 30]},\n",
        "    'svc': {'classifier__C': [0.1, 1, 10]}\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "for name, classifier in classifiers:\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('classifier', classifier)])\n",
        "    # GridSearchCV para encontrar os melhores parâmetros\n",
        "    grid_search = GridSearchCV(pipeline, param_grids[name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_models[name] = grid_search.best_estimator_\n",
        "    print(f\"Melhor modelo para {name}: {grid_search.best_params_}\")\n",
        "\n",
        "for name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Relatório de classificação para o modelo {name}:\")\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyoWUV0uIFtD",
        "outputId": "bd8fce8b-1d0f-414c-d7cf-2b9bbfff2d14"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhor modelo para logreg: {'classifier__C': 0.1}\n",
            "Melhor modelo para rf: {'classifier__n_estimators': 200}\n",
            "Melhor modelo para dt: {'classifier__max_depth': 10}\n",
            "Melhor modelo para svc: {'classifier__C': 10}\n",
            "Relatório de classificação para o modelo logreg:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1790\n",
            "           1       0.68      1.00      0.81      3757\n",
            "\n",
            "    accuracy                           0.68      5547\n",
            "   macro avg       0.34      0.50      0.40      5547\n",
            "weighted avg       0.46      0.68      0.55      5547\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatório de classificação para o modelo rf:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.19      0.28      1790\n",
            "           1       0.71      0.93      0.80      3757\n",
            "\n",
            "    accuracy                           0.69      5547\n",
            "   macro avg       0.63      0.56      0.54      5547\n",
            "weighted avg       0.66      0.69      0.63      5547\n",
            "\n",
            "Relatório de classificação para o modelo dt:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.16      0.25      1790\n",
            "           1       0.70      0.94      0.80      3757\n",
            "\n",
            "    accuracy                           0.69      5547\n",
            "   macro avg       0.63      0.55      0.52      5547\n",
            "weighted avg       0.66      0.69      0.62      5547\n",
            "\n",
            "Relatório de classificação para o modelo svc:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.01      0.03      1790\n",
            "           1       0.68      1.00      0.81      3757\n",
            "\n",
            "    accuracy                           0.68      5547\n",
            "   macro avg       0.70      0.51      0.42      5547\n",
            "weighted avg       0.69      0.68      0.56      5547\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise de Melhor Modelo\n",
        "\n",
        "Após a avaliação de diversos modelos de classificação binária, o modelo de **Floresta Aleatória (Random Forest)** se destacou como o mais promissor para a tarefa de prever comportamentos on-task e off-task em ambientes educacionais. Os resultados obtidos foram comparados baseando-se em métricas de precisão, recall e F1-score para ambas as classes (on-task e off-task).\n",
        "\n",
        "### Resultados do Modelo de Floresta Aleatória:\n",
        "- **Precisão para on-task (1):** 71%\n",
        "- **Recall para on-task (1):** 93%\n",
        "- **F1-score para on-task (1):** 80%\n",
        "- **Precisão para off-task (0):** 57%\n",
        "- **Recall para off-task (0):** 18%\n",
        "- **F1-score para off-task (0):** 27%\n",
        "\n",
        "### Justificativa para a Escolha:\n",
        "O modelo de Floresta Aleatória demonstrou um equilíbrio relativamente melhor entre precisão e recall para ambas as classes em comparação com os outros modelos testados. Apesar de os valores de recall e F1-score para a classe off-task ainda serem baixos, este modelo conseguiu atingir uma precisão e F1-score consideráveis para a classe on-task, que compõe a maioria dos casos.\n",
        "\n",
        "### Importância das Métricas:\n",
        "O **recall** é crucial, especialmente para a classe off-task, pois indica a capacidade do modelo de capturar todos os casos relevantes de desengajamento. Um alto recall na classe off-task significa que o sistema é capaz de identificar eficientemente os alunos que precisam de atenção adicional, possibilitando intervenções educacionais mais eficazes.\n",
        "\n",
        "O **F1-score** também é uma métrica importante, pois equilibra a precisão e o recall, sendo particularmente útil em situações com classes desbalanceadas como esta. O F1-score mais alto para on-task mostra que o modelo é competente em identificar o engajamento dos alunos, mas é necessário melhorar o F1-score para off-task para tornar o modelo mais útil em ambientes educacionais práticos.\n"
      ],
      "metadata": {
        "id": "qqMMz96eIXoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------"
      ],
      "metadata": {
        "id": "o3W6aomUIwnv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baeOjdm12TQ1",
        "outputId": "8d96b4cf-ff0a-4b0f-f9a0-81842dd86889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores parâmetros encontrados: {'feature_selection__n_features_to_select': 10}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.08      0.14       859\n",
            "           1       0.70      0.97      0.81      1915\n",
            "\n",
            "    accuracy                           0.69      2774\n",
            "   macro avg       0.62      0.52      0.48      2774\n",
            "weighted avg       0.65      0.69      0.60      2774\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "##Criação de Nova Feature\n",
        "\n",
        "# Usando uma amostra menor para testes iniciais (50% dos dados)\n",
        "data_sample = data.sample(frac=0.5, random_state=42)\n",
        "\n",
        "# Engenharia de features:\n",
        "data_sample['Interaction'] = data_sample['NumACTIVITIES'] * data_sample['NumFORMATS']\n",
        "\n",
        "# Pré-processamento:\n",
        "features = data_sample.drop('ONTASK', axis=1)\n",
        "target = data_sample['ONTASK'].map({'Y': 1, 'N': 0})\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Transformações e Feature Engineering:\n",
        "numeric_features = features.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = features.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "#Treinamento e Avaliação com GridSearchCV e Pipeline\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=2))  # Redução de dimensionalidade como exemplo de engenharia de features\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "#Implementação do RFE\n",
        "# Modelo e Seleção de Features com modelo mais leve para RFE: (2.5)\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('feature_selection', RFE(estimator=LogisticRegression(), n_features_to_select=5)),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, max_depth=10))\n",
        "])\n",
        "\n",
        "# Configuração do GridSearchCV:\n",
        "param_grid = {\n",
        "    'feature_selection__n_features_to_select': [5, 10]\n",
        "}\n",
        "\n",
        "#(2.6)\n",
        "search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1)\n",
        "search.fit(X_train, y_train)\n",
        "print(\"Melhores parâmetros encontrados:\", search.best_params_)\n",
        "\n",
        "# Avaliação:\n",
        "y_pred = search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import pandas as pd\n",
        "\n",
        "# Suponhamos que temos um DataFrame chamado `data` já carregado\n",
        "features = data[['NumACTIVITIES', 'NumFORMATS']]  # Exemplo de seleção de algumas features numéricas\n",
        "\n",
        "# Criação do objeto PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "\n",
        "# Fit e transform para criar novas features polinomiais\n",
        "features_poly = poly.fit_transform(features)\n",
        "\n",
        "# Convertendo as features polinomiais de volta para um DataFrame\n",
        "features_poly_df = pd.DataFrame(features_poly, columns=poly.get_feature_names_out(features.columns))\n",
        "\n",
        "# Exibindo as novas features criadas\n",
        "print(features_poly_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SnGF-r5GVLq",
        "outputId": "4d107890-cdbe-4cd6-db83-c7db8999cd3f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumACTIVITIES  NumFORMATS  NumACTIVITIES^2  NumACTIVITIES NumFORMATS  \\\n",
            "0            4.0         2.0             16.0                       8.0   \n",
            "1            4.0         2.0             16.0                       8.0   \n",
            "2            4.0         2.0             16.0                       8.0   \n",
            "3            4.0         2.0             16.0                       8.0   \n",
            "4            4.0         2.0             16.0                       8.0   \n",
            "\n",
            "   NumFORMATS^2  \n",
            "0           4.0  \n",
            "1           4.0  \n",
            "2           4.0  \n",
            "3           4.0  \n",
            "4           4.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explicação da Feature Criada (2.2)\n",
        "### Comentário sobre Resultados no Notebook / Reavaliação Pós-RFE\n",
        "\n",
        "A razão pela qual essa feature foi criada utilizando **Polynomial Features** é baseada na possibilidade de revelar relações complexas e não-lineares entre as variáveis existentes que modelos lineares simples podem não conseguir capturar.\n",
        "\n",
        "### Benefício\n",
        "\n",
        "1. **Melhor Desempenho do Modelo**: Modelos que incluem essas novas features podem ter um desempenho melhor, pois estão equipados para entender a complexidade dos dados de forma mais eficaz.\n",
        "\n",
        "Essa técnica é apenas uma entre várias que podem ser utilizadas para enriquecer o conjunto de dados e potencialmente melhorar os modelos de predição em tarefas de classificação ou regressão.\n"
      ],
      "metadata": {
        "id": "hyJnt6DiGtPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------"
      ],
      "metadata": {
        "id": "prnthV9uH2dC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise dos resultados:\n",
        "\n",
        "## Resultados da Aula 8 (2.4)\n",
        "\n",
        "- **Modelos Utilizados**:\n",
        "  - Regressão Logística (LogReg)\n",
        "  - Floresta Aleatória (RF)\n",
        "  - Árvore de Decisão (DT)\n",
        "  - Máquinas de Vetores de Suporte (SVC)\n",
        "\n",
        "- **Desempenho Geral**:\n",
        "  - Os modelos mostraram uma tendência de precisão alta para a classe positiva (1).\n",
        "\n",
        "## Resultados da Aula 10\n",
        "\n",
        "Após a implementação de melhorias, incluindo engenharia de features e seleção de features via `GridSearchCV` e `RFE`, os resultados foram:\n",
        "\n",
        "- **Melhores parâmetros encontrados**: `{'feature_selection__n_features_to_select': 10}`\n",
        "- **Métricas de Desempenho**:\n",
        "  - precision recall f1-score support\n",
        "  - 0 0.54 0.08 0.14 859\n",
        "  - 1 0.70 0.97 0.81 1915\n",
        "\n",
        "- **Accuracy**: 69%\n",
        "- **Macro avg**:\n",
        "  - Precision: 0.62\n",
        "  - Recall: 0.52\n",
        "  - F1-score: 0.48\n",
        "- **Weighted avg**:\n",
        "  - Precision: 0.65\n",
        "  - Recall: 0.69\n",
        "  - F1-score: 0.60\n",
        "\n",
        "## Análise Comparativa (2.7) / Análise Crítica dos Resultados Finais\n",
        "\n",
        "- **Complexidade vs. Desempenho**: A introdução de engenharia de features e a seleção focada ajudaram a potencialmente simplificar o modelo, apesar de o desempenho em termos de precisão e `recall` ter se mantido similar.\n",
        "- **Desafios Continuados**: O `recall` dessa classe ainda é baixo.\n",
        "- **Benefícios da Seleção de Features**: A Aula 10 focou em refinar o modelo para torná-lo mais gerenciável e potencialmente mais explicável, o que é benéfico para entender o impacto das variáveis no engajamento dos alunos.\n",
        "\n",
        "\n",
        "## Conclusão\n",
        "\n",
        "Ao analisar criticamente os resultados finais dos modelos das aulas 8 e 10, fica evidente que, apesar das melhorias implementadas na Aula 10, como engenharia de features e seleção de features via RFE (Recursive Feature Elimination), o aumento no desempenho geral do modelo foi baixo. Os modelos continuam a apresentar uma tendência de alta precisão e recall para a classe positiva (engajados), mas lutam significativamente com a classe negativa (não engajados), evidenciado pelo baixo recall nesta categoria. Essa dificuldade em identificar corretamente os alunos desengajados é uma limitação crítica, pois sugere que o modelo, embora eficaz em capturar a maioria dos casos de engajamento, falha em alertar sobre os casos de desengajamento, que são crucialmente importantes para intervenções pedagógicas.\n",
        "\n",
        "Essa limitação pode ser atribuída à natureza dos dados ou à seleção de features que, apesar do processo de otimização, pode ainda não estar capturando as nuances que diferenciam eficazmente ambas as classes. Também pode indicar a necessidade de revisitar o balanceamento das classes nos dados de treinamento ou de explorar modelos ou métodos de aprendizado de máquina alternativos que possam lidar melhor com desequilíbrios de classe. A implementação de técnicas como o ajuste de pesos de classe no modelo de RandomForest ou a experimentação com algoritmos mais sensíveis a desequilíbrios poderia potencialmente melhorar o desempenho na previsão de alunos desengajados.\n",
        "\n",
        "Portanto, enquanto a Aula 10 fez progressos no refinamento do modelo, ainda há um caminho significativo a ser explorado na melhoria da capacidade do modelo de atuar de forma eficaz em todas as frentes, o que é essencial para seu uso prático em ambientes educacionais onde identificar ambos, engajamento e desengajamento, é importante."
      ],
      "metadata": {
        "id": "J3q9KVFH20hZ"
      }
    }
  ]
}